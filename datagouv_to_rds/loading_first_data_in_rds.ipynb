{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; background-color:blue; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Premier chargement en base de données rds</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Import des librairies et des fichiers annexes</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies pour la décompression de fichiers\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "\n",
    "# Librairies pour le scrapping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Visualisation de données\n",
    "import pandas as pd\n",
    "\n",
    "# Connection à RDS\n",
    "from connection import db,cursor,s3,bucket_name,connection_with_sqlaclchemy\n",
    "\n",
    "# datas processing\n",
    "import datas_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Création des tables dans la base de données</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La table COMMUNES à bien été créée\n",
      "La table DEPARTEMENTS à bien été créée\n",
      "La table REGIONS à bien été créée\n",
      "La table TYPES_BIENS à bien été créée\n",
      "La table VENTES à bien été créée\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS datagouv;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "query=\"\"\"\n",
    "USE datagouv;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Lecture de fichier create_tables\n",
    "with open('create_tables.sql') as file:\n",
    "    sql_queries = file.read()\n",
    "try :\n",
    "    for query in sql_queries.split(';')[:-1]:\n",
    "        query = query.strip()\n",
    "        cursor.execute(query)\n",
    "except Exception as e:\n",
    "    print(f\"Erreur dans la creation des tables : {e}\")\n",
    "    db.rollback()\n",
    "\n",
    "query=\"\"\"\n",
    "SHOW TABLES;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for table in tables:\n",
    "    print(f\"La table {table[0]} à bien été créée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Récupération des datas sur :<br>\n",
    "  L'api https://geo.api.gouv.fr/ <br>\n",
    "  et Scrapping des datas sur :\n",
    "  https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les régions depuis l'api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_REGION</th>\n",
       "      <th>Name_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Île-de-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Centre-Val de Loire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Bourgogne-Franche-Comté</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Normandie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Hauts-de-France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_REGION              Name_region\n",
       "0        11            Île-de-France\n",
       "1        24      Centre-Val de Loire\n",
       "2        27  Bourgogne-Franche-Comté\n",
       "3        28                Normandie\n",
       "4        32          Hauts-de-France"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_regions = \"https://geo.api.gouv.fr/regions\"\n",
    "response_regions = requests.get(url_regions)\n",
    "data_regions = response_regions.json()\n",
    "df_regions = pd.DataFrame(data_regions)\n",
    "df_regions = df_regions.loc[:,[\"code\",\"nom\"]]\n",
    "df_regions = df_regions.drop_duplicates()\n",
    "df_regions.columns = ['ID_REGION','Name_region']\n",
    "df_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_region: 01 -- Nom region : Guadeloupe\n",
      "ID_region: 02 -- Nom region : Martinique\n",
      "ID_region: 03 -- Nom region : Guyane\n",
      "ID_region: 04 -- Nom region : La Réunion\n",
      "ID_region: 06 -- Nom region : Mayotte\n",
      "ID_region: 11 -- Nom region : Île-de-France\n",
      "ID_region: 24 -- Nom region : Centre-Val de Loire\n",
      "ID_region: 27 -- Nom region : Bourgogne-Franche-Comté\n",
      "ID_region: 28 -- Nom region : Normandie\n",
      "ID_region: 32 -- Nom region : Hauts-de-France\n",
      "ID_region: 44 -- Nom region : Grand Est\n",
      "ID_region: 52 -- Nom region : Pays de la Loire\n",
      "ID_region: 53 -- Nom region : Bretagne\n",
      "ID_region: 75 -- Nom region : Nouvelle-Aquitaine\n",
      "ID_region: 76 -- Nom region : Occitanie\n",
      "ID_region: 84 -- Nom region : Auvergne-Rhône-Alpes\n",
      "ID_region: 93 -- Nom region : Provence-Alpes-Côte d'Azur\n",
      "ID_region: 94 -- Nom region : Corse\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table REGIONS\n",
    "query=\"\"\"\n",
    "USE datagouv;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "df_regions['ID_REGION'] = df_regions.ID_REGION.astype(str)\n",
    "df_regions['Name_region'] = df_regions.Name_region.astype(str)\n",
    "\n",
    "for index, row in df_regions.iterrows():\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO REGIONS (ID_REGION,Name_region)\n",
    "    VALUES (%s,%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(row[\"ID_REGION\"],row[\"Name_region\"]))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM REGIONS\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "regions = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for region in regions:\n",
    "    print(f\"ID_region: {region[0]} -- Nom region : {region[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les départements depuis l'api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_DEPT</th>\n",
       "      <th>Name_departement</th>\n",
       "      <th>ID_REGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Ain</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>Allier</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_DEPT         Name_departement ID_REGION\n",
       "0      01                      Ain        84\n",
       "1      02                    Aisne        32\n",
       "2      03                   Allier        84\n",
       "3      04  Alpes-de-Haute-Provence        93\n",
       "4      05             Hautes-Alpes        93"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération des codes departements, noms departements et code régions\n",
    "url = \"https://geo.api.gouv.fr/departements\"\n",
    "response = requests.get(url)\n",
    "data_dpts = response.json()\n",
    "df_depts = pd.DataFrame(data_dpts)\n",
    "df_depts = df_depts.loc[:,[\"code\",\"nom\",\"codeRegion\"]]\n",
    "df_depts = df_depts.drop_duplicates()\n",
    "df_depts.columns = ['ID_DEPT', 'Name_departement', 'ID_REGION']\n",
    "df_depts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id departement: 01 -- Nom departement : Ain -- Id region : 84\n",
      "Id departement: 02 -- Nom departement : Aisne -- Id region : 32\n",
      "Id departement: 03 -- Nom departement : Allier -- Id region : 84\n",
      "Id departement: 04 -- Nom departement : Alpes-de-Haute-Provence -- Id region : 93\n",
      "Id departement: 05 -- Nom departement : Hautes-Alpes -- Id region : 93\n",
      "Id departement: 06 -- Nom departement : Alpes-Maritimes -- Id region : 93\n",
      "Id departement: 07 -- Nom departement : Ardèche -- Id region : 84\n",
      "Id departement: 08 -- Nom departement : Ardennes -- Id region : 44\n",
      "Id departement: 09 -- Nom departement : Ariège -- Id region : 76\n",
      "Id departement: 10 -- Nom departement : Aube -- Id region : 44\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table DEPARTEMENTS\n",
    "for index, row in df_depts.iterrows():\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO DEPARTEMENTS (ID_DEPT, Name_departement,\tID_REGION)\n",
    "    VALUES (%s,%s,%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(row[\"ID_DEPT\"],row[\"Name_departement\"],row[\"ID_REGION\"]))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM DEPARTEMENTS\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "dapartements = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for departement in dapartements:\n",
    "    print(f\"Id departement: {departement[0]} -- Nom departement : {departement[1]} -- Id region : {departement[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les communes depuis l'api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_COMMUNE</th>\n",
       "      <th>NAME_COMMUNE</th>\n",
       "      <th>ID_DEPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>L'Abergement-Clémenciat</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>L'Abergement-de-Varey</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01004</td>\n",
       "      <td>Ambérieu-en-Bugey</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>Ambérieux-en-Dombes</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01006</td>\n",
       "      <td>Ambléon</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_COMMUNE             NAME_COMMUNE ID_DEPT\n",
       "0      01001  L'Abergement-Clémenciat      01\n",
       "1      01002    L'Abergement-de-Varey      01\n",
       "2      01004        Ambérieu-en-Bugey      01\n",
       "3      01005      Ambérieux-en-Dombes      01\n",
       "4      01006                  Ambléon      01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération des codes communes , noms communes et code départements \n",
    "url = \"https://geo.api.gouv.fr/communes\"\n",
    "response = requests.get(url)\n",
    "data_communes = response.json()\n",
    "df_communes = pd.DataFrame(data_communes)\n",
    "df_communes = df_communes.loc[:,[\"code\",\"nom\",\"codeDepartement\"]]\n",
    "df_communes = df_communes.drop_duplicates()\n",
    "df_communes.columns= [\"ID_COMMUNE\",\"NAME_COMMUNE\",\"ID_DEPT\"]\n",
    "df_communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id commune: 01001 -- Nom commune : L'Abergement-Clémenciat -- Id départment : 01\n",
      "Id commune: 01002 -- Nom commune : L'Abergement-de-Varey -- Id départment : 01\n",
      "Id commune: 01004 -- Nom commune : Ambérieu-en-Bugey -- Id départment : 01\n",
      "Id commune: 01005 -- Nom commune : Ambérieux-en-Dombes -- Id départment : 01\n",
      "Id commune: 01006 -- Nom commune : Ambléon -- Id départment : 01\n",
      "Id commune: 01007 -- Nom commune : Ambronay -- Id départment : 01\n",
      "Id commune: 01008 -- Nom commune : Ambutrix -- Id départment : 01\n",
      "Id commune: 01009 -- Nom commune : Andert-et-Condon -- Id départment : 01\n",
      "Id commune: 01010 -- Nom commune : Anglefort -- Id départment : 01\n",
      "Id commune: 01011 -- Nom commune : Apremont -- Id départment : 01\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table COMMUNES\n",
    "for index, row in df_communes.iterrows():\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO COMMUNES (ID_COMMUNE, NAME_COMMUNE,\tID_DEPT)\n",
    "    VALUES (%s,%s,%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(row[\"ID_COMMUNE\"],row[\"NAME_COMMUNE\"],row[\"ID_DEPT\"]))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM COMMUNES\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "communes = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for commune in communes:\n",
    "    print(f\"Id commune: {commune[0]} -- Nom commune : {commune[1]} -- Id départment : {commune[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id type bien : 1 -- nom : Appartement\n",
      "Id type bien : 2 -- nom : Maison\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table TYPES_BIENS\n",
    "liste_type_local = [\"Appartement\",\"Maison\"]\n",
    "for local in liste_type_local:\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO TYPES_BIENS (NAME_TYPE_BIEN)\n",
    "    VALUES(%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(local))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM TYPES_BIENS\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "types_biens = cursor.fetchall()\n",
    "\n",
    "# Affichage du contenu de la table TYPES_BIENS\n",
    "for i in types_biens:\n",
    "    print(f\"Id type bien : {i[0]} -- nom : {i[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les ventes en webscrapping depuis https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la page web\n",
    "url = 'https://files.data.gouv.fr/geo-dvf/latest/csv/'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Utilisez BeautifulSoup pour analyser le HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018/', '2019/', '2020/', '2021/', '2022/', '2023/']\n"
     ]
    }
   ],
   "source": [
    "# Trouver toutes les balises <a>\n",
    "a_tags = soup.find_all('a')\n",
    "annees=[]\n",
    "# Parcourir chaque balise <a> et extraire le texte ainsi que la date/heure\n",
    "for a_tag in a_tags:\n",
    "    name = a_tag.text.strip()\n",
    "    if name!=\"../\":\n",
    "        annees.append(name)\n",
    "print(annees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Les ventes de l'année 2018/ ont bien été insérées dans RDS\n",
      " Les ventes de l'année 2019/ ont bien été insérées dans RDS\n",
      " Les ventes de l'année 2020/ ont bien été insérées dans RDS\n",
      " Les ventes de l'année 2021/ ont bien été insérées dans RDS\n",
      " Les ventes de l'année 2022/ ont bien été insérées dans RDS\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "USE datagouv;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# La dernière année ne sera pas prise en compte pour tester la mise à jour des \n",
    "# données dans le programme maj_datas.py\n",
    "for annee in annees[:-1] : \n",
    "    url = f'https://files.data.gouv.fr/geo-dvf/latest/csv/{annee}'\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Trouver la balise 'a' qui contient les liens de téléchargement\n",
    "    csv_element = soup.find('pre').find('a', {'href': \"full.csv.gz\"})\n",
    "    csv_link = urljoin(url, csv_element['href'])\n",
    "\n",
    "    # Téléchargement des datas et convertion en dataframe\n",
    "    csv_response = requests.get(csv_link)\n",
    "    if csv_response.status_code == 200:\n",
    "        # Utilisation du buffer pour décompresser le fichier .gz\n",
    "        try :\n",
    "            with BytesIO(csv_response.content) as file_buffer:\n",
    "                with gzip.GzipFile(fileobj=file_buffer, mode='rb') as gz_file:\n",
    "                    df = pd.read_csv(gz_file, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(\"Erreur dans la transformation des données en dataframe :\",e)\n",
    "\n",
    "    else :\n",
    "        print(\"Problème dans le lien de récupération de données !!!\")\n",
    "\n",
    "    # Selection des données\n",
    "    df = datas_processing.select_datas(df)\n",
    "       \n",
    "    # Gestion des valeurs manquantes :\n",
    "    df = datas_processing.nan_management(df)\n",
    "\n",
    "    # Adaptation des données du dataframe au format de la base de données\n",
    "    df = datas_processing.format_data(df)\n",
    "\n",
    "    # Groupement des données sur une seule ligne par id_mutation (vente)\n",
    "    df = datas_processing.grouped_datas(df)\n",
    "\n",
    "    # Suppression de la colonne id_mutation qui est inutile maintant\n",
    "    df = df.iloc[:,1:]\n",
    "\n",
    "    #Suppression des lignes dupliquées\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Utilisation de sqlachemy pour charger les données datagouv dans RDS\n",
    "    # Création de la connection\n",
    "    engine = connection_with_sqlaclchemy(\"datagouv\")\n",
    "\n",
    "    # Correlation entre les colonnes \n",
    "    column_mapping={'date_mutation' : 'DATE_MUTATION',\n",
    "                    'valeur_fonciere' : 'MONTANT',\n",
    "                    'adresse_numero' : 'NUMERO_RUE',\n",
    "                    'adresse_nom_voie': 'RUE',\n",
    "                    'code_postal' :  'CODE_POSTAL',\n",
    "                    'code_commune' : 'ID_COMMUNE',\n",
    "                    'type_local' : 'ID_TYPE_BIEN',\n",
    "                    'nombre_pieces_principales' : 'NB_PIECES',\n",
    "                    'surface_reelle_bati' : 'SURFACE_BATI',\n",
    "                    'surface_terrain' : 'SURFACE_TERRAIN',\n",
    "                    'longitude' : 'LONGITUDE',\n",
    "                    'latitude': 'LATITUDE',\n",
    "                    'dependance' : 'DEPENDANCES'}\n",
    "    df.columns = [column_mapping[col] for col in df.columns]\n",
    "\n",
    "    # Chargement du dataframe dans RDS avec sqlalchemy\n",
    "    df.to_sql(name='VENTES', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# Fermer la connexion\n",
    "engine.dispose()\n",
    "\n",
    "    # # Chargement en base de données\n",
    "    # try :\n",
    "    #     for index,row in df.iterrows():\n",
    "    #         if row[\"type_local\"] == \"Maison\" :\n",
    "    #             type_local_value = 2\n",
    "    #         else :\n",
    "    #             type_local_value = 1\n",
    "    #         query=\"\"\"\n",
    "    #         INSERT IGNORE INTO VENTES (DATE_MUTATION, MONTANT,\n",
    "    #                         NUMERO_RUE, RUE , CODE_POSTAL,ID_COMMUNE,\n",
    "    #                         ID_TYPE_BIEN, NB_PIECES ,\n",
    "    #                         SURFACE_BATI,  SURFACE_TERRAIN,\n",
    "    #                         LONGITUDE, LATITUDE )\n",
    "    #         VALUES (%s,%s,\n",
    "    #                 %s,%s,%s,%s,\n",
    "    #                 %s,%s,\n",
    "    #                 %s,%s,\n",
    "    #                 %s,%s)\n",
    "    #         \"\"\"\n",
    "    #         cursor.execute(query,(row[\"date_mutation\"],row['valeur_fonciere'],\n",
    "    #                     row[\"adresse_numero\"],row[\"adresse_nom_voie\"],row[\"code_postal\"],row[\"code_commune\"],\n",
    "    #                     type_local_value,row[\"nombre_pieces_principales\"],\n",
    "    #                     row[\"surface_reelle_bati\"],row[\"surface_terrain\"],\n",
    "    #                     row[\"longitude\"],row[\"latitude\"]))\n",
    "    #     db.commit()\n",
    "    #     print(f\" Les ventes de l'année {annee} ont bien été insérées dans RDS\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Erreur dans le chargement des données de l'année {annee} dans RDS :\",e)\n",
    "   \n",
    "# cursor.close()\n",
    "# db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h3 style=\"color:white;\">Récupération de la dernière date de mise à jour des données et stockage dans le bucket S3</h3>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-Oct-202320:28-\n"
     ]
    }
   ],
   "source": [
    "date_element = soup.find('pre').contents[-1].strip()\n",
    "date_maj = date_element.replace(\" \",\"\")\n",
    "print(date_maj)\n",
    "\n",
    "# Utilisation de BytesIO pour créer un buffer en mémoire\n",
    "buffer = BytesIO()\n",
    "buffer.write(date_maj.encode('utf-8'))  # Encode la chaîne en UTF-8 avant de l'écrire\n",
    "\n",
    "# Écriture du texte dans le fichier sur S3\n",
    "buffer.seek(0)  # Réinitialise la position de lecture/écriture\n",
    "s3.upload_fileobj(buffer, bucket_name, 'app_immo/last_maj.txt')\n",
    "\n",
    "# Assurez-vous de fermer le buffer BytesIO\n",
    "buffer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-Oct-202320:28-\n"
     ]
    }
   ],
   "source": [
    "# Téléchargement du fichier depuis S3 vers un nouveau buffer\n",
    "buffer_read = BytesIO()\n",
    "s3.download_fileobj(bucket_name, 'app_immo/last_maj.txt', buffer_read)\n",
    "\n",
    "# Lecture du contenu du buffer\n",
    "buffer_read.seek(0)\n",
    "last_maj_saved = buffer_read.read().decode('utf-8')  # Decodez les bytes en UTF-8\n",
    "print(last_maj_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout d'une valeur quelconque pour tester la lamba \n",
    "start_value=\"start_value\"\n",
    "\n",
    "# Utilisation de BytesIO pour créer un buffer en mémoire\n",
    "buffer = BytesIO()\n",
    "buffer.write(start_value.encode('utf-8'))  # Encode la chaîne en UTF-8 avant de l'écrire\n",
    "\n",
    "# Écriture du texte dans le fichier sur S3\n",
    "buffer.seek(0)  # Réinitialise la position de lecture/écriture\n",
    "s3.upload_fileobj(buffer, bucket_name, 'app_immo/last_maj.txt')\n",
    "\n",
    "# Assurez-vous de fermer le buffer BytesIO\n",
    "buffer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
