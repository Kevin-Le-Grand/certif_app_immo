{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; background-color:blue; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Premier chargement en base de données rds</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Import des librairies et des fichiers annexes</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies pour la décompression de fichiers\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "\n",
    "# Librairies pour le scrapping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Visualisation de données\n",
    "import pandas as pd\n",
    "\n",
    "# Connection à RDS\n",
    "from connection import db,cursor,s3,bucket_name\n",
    "\n",
    "# datas processing\n",
    "import datas_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Création des tables dans la base de données</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La table COMMUNES à bien été créée\n",
      "La table DEPARTEMENTS à bien été créée\n",
      "La table REGIONS à bien été créée\n",
      "La table TYPES_BIENS à bien été créée\n",
      "La table VENTES à bien été créée\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS datagouv;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "query=\"\"\"\n",
    "USE datagouv;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Lecture de fichier create_tables\n",
    "with open('create_tables.sql') as file:\n",
    "    sql_queries = file.read()\n",
    "try :\n",
    "    for query in sql_queries.split(';')[:-1]:\n",
    "        query = query.strip()\n",
    "        cursor.execute(query)\n",
    "except Exception as e:\n",
    "    print(f\"Erreur dans la creation des tables : {e}\")\n",
    "    db.rollback()\n",
    "\n",
    "query=\"\"\"\n",
    "SHOW TABLES;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for table in tables:\n",
    "    print(f\"La table {table[0]} à bien été créée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h1 style=\"color:white;\">Récupération des datas sur :<br>\n",
    "  L'api https://geo.api.gouv.fr/ <br>\n",
    "  et Scrapping des datas sur :\n",
    "  https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les régions depuis l'api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_REGION</th>\n",
       "      <th>Name_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Île-de-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Centre-Val de Loire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Bourgogne-Franche-Comté</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Normandie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Hauts-de-France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_REGION              Name_region\n",
       "0        11            Île-de-France\n",
       "1        24      Centre-Val de Loire\n",
       "2        27  Bourgogne-Franche-Comté\n",
       "3        28                Normandie\n",
       "4        32          Hauts-de-France"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_regions = \"https://geo.api.gouv.fr/regions\"\n",
    "response_regions = requests.get(url_regions)\n",
    "data_regions = response_regions.json()\n",
    "df_regions = pd.DataFrame(data_regions)\n",
    "df_regions = df_regions.loc[:,[\"code\",\"nom\"]]\n",
    "df_regions = df_regions.drop_duplicates()\n",
    "df_regions.columns = ['ID_REGION','Name_region']\n",
    "df_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_region: 01 -- Nom region : Guadeloupe\n",
      "ID_region: 02 -- Nom region : Martinique\n",
      "ID_region: 03 -- Nom region : Guyane\n",
      "ID_region: 04 -- Nom region : La Réunion\n",
      "ID_region: 06 -- Nom region : Mayotte\n",
      "ID_region: 11 -- Nom region : Île-de-France\n",
      "ID_region: 24 -- Nom region : Centre-Val de Loire\n",
      "ID_region: 27 -- Nom region : Bourgogne-Franche-Comté\n",
      "ID_region: 28 -- Nom region : Normandie\n",
      "ID_region: 32 -- Nom region : Hauts-de-France\n",
      "ID_region: 44 -- Nom region : Grand Est\n",
      "ID_region: 52 -- Nom region : Pays de la Loire\n",
      "ID_region: 53 -- Nom region : Bretagne\n",
      "ID_region: 75 -- Nom region : Nouvelle-Aquitaine\n",
      "ID_region: 76 -- Nom region : Occitanie\n",
      "ID_region: 84 -- Nom region : Auvergne-Rhône-Alpes\n",
      "ID_region: 93 -- Nom region : Provence-Alpes-Côte d'Azur\n",
      "ID_region: 94 -- Nom region : Corse\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table REGIONS\n",
    "query=\"\"\"\n",
    "USE datagouv;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "df_regions['ID_REGION'] = df_regions.ID_REGION.astype(str)\n",
    "df_regions['Name_region'] = df_regions.Name_region.astype(str)\n",
    "\n",
    "for index, row in df_regions.iterrows():\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO REGIONS (ID_REGION,Name_region)\n",
    "    VALUES (%s,%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(row[\"ID_REGION\"],row[\"Name_region\"]))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM REGIONS\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "regions = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for region in regions:\n",
    "    print(f\"ID_region: {region[0]} -- Nom region : {region[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les départements depuis l'api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_DEPT</th>\n",
       "      <th>Name_departement</th>\n",
       "      <th>ID_REGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Ain</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>Allier</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_DEPT         Name_departement ID_REGION\n",
       "0      01                      Ain        84\n",
       "1      02                    Aisne        32\n",
       "2      03                   Allier        84\n",
       "3      04  Alpes-de-Haute-Provence        93\n",
       "4      05             Hautes-Alpes        93"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération des codes departements, noms departements et code régions\n",
    "url = \"https://geo.api.gouv.fr/departements\"\n",
    "response = requests.get(url)\n",
    "data_dpts = response.json()\n",
    "df_depts = pd.DataFrame(data_dpts)\n",
    "df_depts = df_depts.loc[:,[\"code\",\"nom\",\"codeRegion\"]]\n",
    "df_depts = df_depts.drop_duplicates()\n",
    "df_depts.columns = ['ID_DEPT', 'Name_departement', 'ID_REGION']\n",
    "df_depts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id departement: 01 -- Nom departement : Ain -- Id region : 84\n",
      "Id departement: 02 -- Nom departement : Aisne -- Id region : 32\n",
      "Id departement: 03 -- Nom departement : Allier -- Id region : 84\n",
      "Id departement: 04 -- Nom departement : Alpes-de-Haute-Provence -- Id region : 93\n",
      "Id departement: 05 -- Nom departement : Hautes-Alpes -- Id region : 93\n",
      "Id departement: 06 -- Nom departement : Alpes-Maritimes -- Id region : 93\n",
      "Id departement: 07 -- Nom departement : Ardèche -- Id region : 84\n",
      "Id departement: 08 -- Nom departement : Ardennes -- Id region : 44\n",
      "Id departement: 09 -- Nom departement : Ariège -- Id region : 76\n",
      "Id departement: 10 -- Nom departement : Aube -- Id region : 44\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table DEPARTEMENTS\n",
    "for index, row in df_depts.iterrows():\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO DEPARTEMENTS (ID_DEPT, Name_departement,\tID_REGION)\n",
    "    VALUES (%s,%s,%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(row[\"ID_DEPT\"],row[\"Name_departement\"],row[\"ID_REGION\"]))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM DEPARTEMENTS\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "dapartements = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for departement in dapartements:\n",
    "    print(f\"Id departement: {departement[0]} -- Nom departement : {departement[1]} -- Id region : {departement[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les communes depuis l'api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_COMMUNE</th>\n",
       "      <th>NAME_COMMUNE</th>\n",
       "      <th>ID_DEPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>L'Abergement-Clémenciat</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>L'Abergement-de-Varey</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01004</td>\n",
       "      <td>Ambérieu-en-Bugey</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>Ambérieux-en-Dombes</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01006</td>\n",
       "      <td>Ambléon</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_COMMUNE             NAME_COMMUNE ID_DEPT\n",
       "0      01001  L'Abergement-Clémenciat      01\n",
       "1      01002    L'Abergement-de-Varey      01\n",
       "2      01004        Ambérieu-en-Bugey      01\n",
       "3      01005      Ambérieux-en-Dombes      01\n",
       "4      01006                  Ambléon      01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération des codes communes , noms communes et code départements \n",
    "url = \"https://geo.api.gouv.fr/communes\"\n",
    "response = requests.get(url)\n",
    "data_communes = response.json()\n",
    "df_communes = pd.DataFrame(data_communes)\n",
    "df_communes = df_communes.loc[:,[\"code\",\"nom\",\"codeDepartement\"]]\n",
    "df_communes = df_communes.drop_duplicates()\n",
    "df_communes.columns= [\"ID_COMMUNE\",\"NAME_COMMUNE\",\"ID_DEPT\"]\n",
    "df_communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id commune: 01001 -- Nom commune : L'Abergement-Clémenciat -- Id départment : 01\n",
      "Id commune: 01002 -- Nom commune : L'Abergement-de-Varey -- Id départment : 01\n",
      "Id commune: 01004 -- Nom commune : Ambérieu-en-Bugey -- Id départment : 01\n",
      "Id commune: 01005 -- Nom commune : Ambérieux-en-Dombes -- Id départment : 01\n",
      "Id commune: 01006 -- Nom commune : Ambléon -- Id départment : 01\n",
      "Id commune: 01007 -- Nom commune : Ambronay -- Id départment : 01\n",
      "Id commune: 01008 -- Nom commune : Ambutrix -- Id départment : 01\n",
      "Id commune: 01009 -- Nom commune : Andert-et-Condon -- Id départment : 01\n",
      "Id commune: 01010 -- Nom commune : Anglefort -- Id départment : 01\n",
      "Id commune: 01011 -- Nom commune : Apremont -- Id départment : 01\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table COMMUNES\n",
    "for index, row in df_communes.iterrows():\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO COMMUNES (ID_COMMUNE, NAME_COMMUNE,\tID_DEPT)\n",
    "    VALUES (%s,%s,%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(row[\"ID_COMMUNE\"],row[\"NAME_COMMUNE\"],row[\"ID_DEPT\"]))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM COMMUNES\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "communes = cursor.fetchall()\n",
    "\n",
    "# Afficher les tables\n",
    "for commune in communes:\n",
    "    print(f\"Id commune: {commune[0]} -- Nom commune : {commune[1]} -- Id départment : {commune[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id type bien : 1 -- nom : Appartement\n",
      "Id type bien : 2 -- nom : Maison\n"
     ]
    }
   ],
   "source": [
    "# Insertion dans la table TYPES_BIENS\n",
    "liste_type_local = [\"Appartement\",\"Maison\"]\n",
    "for local in liste_type_local:\n",
    "    query=\"\"\"\n",
    "    INSERT IGNORE INTO TYPES_BIENS (NAME_TYPE_BIEN)\n",
    "    VALUES(%s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query,(local))\n",
    "db.commit()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM TYPES_BIENS\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "types_biens = cursor.fetchall()\n",
    "\n",
    "# Affichage du contenu de la table TYPES_BIENS\n",
    "for i in types_biens:\n",
    "    print(f\"Id type bien : {i[0]} -- nom : {i[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Les ventes en webscrapping depuis https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la page web\n",
    "url = 'https://files.data.gouv.fr/geo-dvf/latest/csv/'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Utilisez BeautifulSoup pour analyser le HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018/', '2019/', '2020/', '2021/', '2022/', '2023/']\n"
     ]
    }
   ],
   "source": [
    "# Trouver toutes les balises <a>\n",
    "a_tags = soup.find_all('a')\n",
    "annees=[]\n",
    "# Parcourir chaque balise <a> et extraire le texte ainsi que la date/heure\n",
    "for a_tag in a_tags:\n",
    "    name = a_tag.text.strip()\n",
    "    if name!=\"../\":\n",
    "        annees.append(name)\n",
    "print(annees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['code_communetype_local'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/kevin/workspace/certif_app_immo/datagouv_to_rds/loading_first_data_in_rds.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kevin/workspace/certif_app_immo/datagouv_to_rds/loading_first_data_in_rds.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProblème dans le lien de récupération de données !!!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kevin/workspace/certif_app_immo/datagouv_to_rds/loading_first_data_in_rds.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Selection des données\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kevin/workspace/certif_app_immo/datagouv_to_rds/loading_first_data_in_rds.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m datas_processing\u001b[39m.\u001b[39;49mselect_datas(df)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kevin/workspace/certif_app_immo/datagouv_to_rds/loading_first_data_in_rds.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Gestion des valeurs manquantes :\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kevin/workspace/certif_app_immo/datagouv_to_rds/loading_first_data_in_rds.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m datas_processing\u001b[39m.\u001b[39mnan_management(df)\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/datas_processing.py:25\u001b[0m, in \u001b[0;36mselect_datas\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect_datas\u001b[39m(df : pd\u001b[39m.\u001b[39mDataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m      4\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m    Fonction permettant de sélectionner les données parmis celle disponibles.  \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m        - latitude\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mloc[(df\u001b[39m.\u001b[39;49mnature_mutation\u001b[39m==\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mVente\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m&\u001b[39;49m ((df\u001b[39m.\u001b[39;49mtype_local\u001b[39m==\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMaison\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m|\u001b[39;49m (df\u001b[39m.\u001b[39;49mtype_local\u001b[39m==\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAppartement\u001b[39;49m\u001b[39m\"\u001b[39;49m)),\n\u001b[1;32m     26\u001b[0m                                           [\u001b[39m\"\u001b[39;49m\u001b[39mdate_mutation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mvaleur_fonciere\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m                                            \u001b[39m\"\u001b[39;49m\u001b[39madresse_numero\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39madresse_nom_voie\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m                                            \u001b[39m\"\u001b[39;49m\u001b[39mcode_postal\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mcode_commune\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     29\u001b[0m                                            \u001b[39m\"\u001b[39;49m\u001b[39mtype_local\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mnombre_pieces_principales\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m                                            \u001b[39m\"\u001b[39;49m\u001b[39msurface_reelle_bati\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39msurface_terrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m                                            \u001b[39m\"\u001b[39;49m\u001b[39mlongitude\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlatitude\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexing.py:1289\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexing.py:955\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    953\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 955\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    956\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1334\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1271\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1273\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1464\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/certif_app_immo/datagouv_to_rds/.venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['code_communetype_local'] not in index\""
     ]
    }
   ],
   "source": [
    "# La dernière année ne sera pas prise en compte pour tester la mise à jour des \n",
    "# données dans le programme maj_datas.py\n",
    "for annee in annees[:-1] : \n",
    "    url = f'https://files.data.gouv.fr/geo-dvf/latest/csv/{annee}'\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Trouver la balise 'a' qui contient les liens de téléchargement\n",
    "    csv_element = soup.find('pre').find('a', {'href': \"full.csv.gz\"})\n",
    "    csv_link = urljoin(url, csv_element['href'])\n",
    "\n",
    "    # Téléchargement des datas et convertion en dataframe\n",
    "    csv_response = requests.get(csv_link)\n",
    "    if csv_response.status_code == 200:\n",
    "        # Utilisation du buffer pour décompresser le fichier .gz\n",
    "        try :\n",
    "            with BytesIO(csv_response.content) as file_buffer:\n",
    "                with gzip.GzipFile(fileobj=file_buffer, mode='rb') as gz_file:\n",
    "                    df = pd.read_csv(gz_file, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(\"Erreur dans la transformation des données en dataframe :\",e)\n",
    "\n",
    "    else :\n",
    "        print(\"Problème dans le lien de récupération de données !!!\")\n",
    "\n",
    "    # Selection des données\n",
    "    datas_processing.select_datas(df)\n",
    "       \n",
    "    # Gestion des valeurs manquantes :\n",
    "    datas_processing.nan_management(df)\n",
    "\n",
    "    # Adaptation des données du dataframe au format de la base de données\n",
    "    datas_processing.format_data(df)\n",
    "\n",
    "    #Suppression des lignes dupliquées\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Chargement en base de données\n",
    "    try :\n",
    "        for index,row in df.iterrows():\n",
    "            query=\"\"\"\n",
    "            INSERT IGNORE INTO VENTES (DATE_MUTATION, MONTANT,\n",
    "                            NUMERO_RUE, RUE , CODE_POSTAL,ID_COMMUNE,\n",
    "                            ID_TYPE_BIEN, NB_PIECES ,\n",
    "                            SURFACE_BATI,  SURFACE_TERRAIN,\n",
    "                            LONGITUDE, LATITUDE )\n",
    "            VALUES (%s,%s,\n",
    "                    %s,%s,%s,%s,\n",
    "                    (SELECT ID_TYPE_BIEN FROM TYPES_BIENS WHERE NAME_TYPE_BIEN=%s),%s,\n",
    "                    %s,%s,\n",
    "                    %s,%s)\n",
    "            \"\"\"\n",
    "            cursor.execute(query,(row[\"date_mutation\"],row['valeur_fonciere'],\n",
    "                        row[\"adresse_numero\"],row[\"adresse_nom_voie\"],row[\"code_postal\"],row[\"code_commune\"],\n",
    "                        row[\"type_local\"],row[\"nombre_pieces_principales\"],\n",
    "                        row[\"surface_reelle_bati\"],row[\"surface_terrain\"],\n",
    "                        row[\"longitude\"],row[\"latitude\"]))\n",
    "        db.commit()\n",
    "        print(f\" Les ventes de l'année {annee} ont bien été insérées dans RDS\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur dans le chargement des données de l'année {annee} dans RDS :\",e)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:10px;\">\n",
    "  <h3 style=\"color:white;\">Récupération de la dernière date de mise à jour des données et stockage dans le bucket S3</h3>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-Oct-202320:28-\n"
     ]
    }
   ],
   "source": [
    "date_element = soup.find('pre').contents[-1].strip()\n",
    "date_maj = date_element.replace(\" \",\"\")\n",
    "print(date_maj)\n",
    "\n",
    "# Utilisation de BytesIO pour créer un buffer en mémoire\n",
    "buffer = BytesIO()\n",
    "buffer.write(date_maj.encode('utf-8'))  # Encode la chaîne en UTF-8 avant de l'écrire\n",
    "\n",
    "# Écriture du texte dans le fichier sur S3\n",
    "buffer.seek(0)  # Réinitialise la position de lecture/écriture\n",
    "s3.upload_fileobj(buffer, bucket_name, 'app_immo/last_maj.txt')\n",
    "\n",
    "# Assurez-vous de fermer le buffer BytesIO\n",
    "buffer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-Oct-202320:28-\n"
     ]
    }
   ],
   "source": [
    "# Téléchargement du fichier depuis S3 vers un nouveau buffer\n",
    "buffer_read = BytesIO()\n",
    "s3.download_fileobj(bucket_name, 'app_immo/last_maj.txt', buffer_read)\n",
    "\n",
    "# Lecture du contenu du buffer\n",
    "buffer_read.seek(0)\n",
    "last_maj_saved = buffer_read.read().decode('utf-8')  # Decodez les bytes en UTF-8\n",
    "print(last_maj_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout d'une valeur quelconque pour tester la lamba \n",
    "start_value=\"start_value\"\n",
    "\n",
    "# Utilisation de BytesIO pour créer un buffer en mémoire\n",
    "buffer = BytesIO()\n",
    "buffer.write(start_value.encode('utf-8'))  # Encode la chaîne en UTF-8 avant de l'écrire\n",
    "\n",
    "# Écriture du texte dans le fichier sur S3\n",
    "buffer.seek(0)  # Réinitialise la position de lecture/écriture\n",
    "s3.upload_fileobj(buffer, bucket_name, 'app_immo/last_maj.txt')\n",
    "\n",
    "# Assurez-vous de fermer le buffer BytesIO\n",
    "buffer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
