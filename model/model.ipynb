{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Création d'un modèle simple</h1>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suite à l'EDA (Analyse exploratoire de données) réalisé précédemment, nous allons créer dans ce notebook, un modèle simple de régression linéaire en utilisant l'algorithme d'apprentissage automatique RandomForestRegressor. La même préparation de données sera effectuée et on conservera uniquement les variables SURFACE_BATi et NB_PIECES. Le but est de mettre en place le monitoring avec MLFlow et de pouvoir livrer la première version de l'application au plus vite. Les performances de ce premier modèle ne seront donc, dans un premier temps, pas très bonne.\n",
    "#### Par la suite, dans d'autres fichiers python nous pourrons améliorer les prédictions en changeant d'algorithme d'apprentissage ou, en créant un modèle par région et en ajoutant des variables comme par exemple le type de bien, une information sur la zone de prix (référence aux cartes de baromètre des prix réalisé avec folium), un coefficient permettant d'ajuster le prix dans le temps...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Import des librairies</h1>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de données\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Récupération et nettoyage des données</h1></div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SURFACE_BATI</th>\n",
       "      <th>NB_PIECES</th>\n",
       "      <th>NAME_TYPE_BIEN</th>\n",
       "      <th>Name_region</th>\n",
       "      <th>MONTANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233</td>\n",
       "      <td>6</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>247000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN           Name_region  MONTANT\n",
       "0           233          6         Maison  Auvergne-Rhône-Alpes   450000\n",
       "1           140          5         Maison  Auvergne-Rhône-Alpes   270600\n",
       "2            88          4         Maison  Auvergne-Rhône-Alpes   172000\n",
       "3            81          3    Appartement  Auvergne-Rhône-Alpes   131500\n",
       "4           159          5         Maison  Auvergne-Rhône-Alpes   247000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération des données\n",
    "df = pd.read_csv(\"datas_rds.csv\", low_memory=False)\n",
    "# Sélection des données non nulles\n",
    "df = df.loc[(df.MONTANT>0) & (df.NB_PIECES>0) & (df.SURFACE_BATI>0),:]\n",
    "# Suppression des valeurs extremes en région Bretagne\n",
    "df = df[~((df.Name_region==\"Bretagne\")&(df.MONTANT>6.5e6))]\n",
    "# Sélection des données\n",
    "df = df.loc[:,[\"SURFACE_BATI\",\"NB_PIECES\",\"NAME_TYPE_BIEN\",\"Name_region\",\"MONTANT\"]]\n",
    "# Suppression des lignes dupliquées\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Étant donné que nous créons un modèle unique, qu'au sein d'une même région il peut y avoir une grosse différence de prix entre deux bien d'une même surface (exemple entre la côte et les terres) et que nous ne pouvons pas ajouter la commune dans l'entraînement du modèle, nous allons donc supprimer les outliers(valeurs extremes) afin d'éviter le sur-ajustement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SURFACE_BATI</th>\n",
       "      <th>NB_PIECES</th>\n",
       "      <th>NAME_TYPE_BIEN</th>\n",
       "      <th>Name_region</th>\n",
       "      <th>MONTANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233</td>\n",
       "      <td>6</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>Maison</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>247000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN           Name_region  MONTANT\n",
       "0           233          6         Maison  Auvergne-Rhône-Alpes   450000\n",
       "1           140          5         Maison  Auvergne-Rhône-Alpes   270600\n",
       "2            88          4         Maison  Auvergne-Rhône-Alpes   172000\n",
       "3            81          3    Appartement  Auvergne-Rhône-Alpes   131500\n",
       "4           159          5         Maison  Auvergne-Rhône-Alpes   247000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des outliers afin de moins perturber le modèle lors de l'apprentissage\n",
    "def filtrer_outliers(groupe):\n",
    "    Q1 = groupe['MONTANT'].quantile(0.25)\n",
    "    Q3 = groupe['MONTANT'].quantile(0.75)\n",
    "    IQR = Q3 - Q1 # Range interquartile\n",
    "    # Convention sur la statistique de l'IQR pour determiner les outliers\n",
    "    borne_inf = Q1 - 1.5 * IQR\n",
    "    borne_sup = Q3 + 1.5 * IQR\n",
    "    return groupe[(groupe['MONTANT'] >= borne_inf) & (groupe['MONTANT'] <= borne_sup)]\n",
    "\n",
    "df = df.groupby('Name_region').apply(filtrer_outliers)\n",
    "# Rest de L'index\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il reste 2421765 ventes pour réaliser le modèle\n"
     ]
    }
   ],
   "source": [
    "print(f\"Il reste {df.shape[0]} ventes pour réaliser le modèle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Labellisation et Standardisation des données</h1>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "\n",
    "def encod_scal(df : pd.DataFrame) -> (pd.DataFrame , dict, dict,list, list):\n",
    "    \"\"\" \n",
    "    Fonction permettant de labelliser puis de standardiser un Data frame  \n",
    "\n",
    "    Args :\n",
    "    - df (pd.DataFrame) : Les données à labelliser puis standardiser\n",
    "\n",
    "    Return :\n",
    "    - df (pd.DataFrame) : Les données labellisées et standardisées\n",
    "    - encoders (dict) : Dictionnaire stockant les encodeurs pour chaque variable catégorielle\n",
    "    - scalers (dict) : Dictionnaire stockant les scalers pour chaque variable numérique\n",
    "    - non_numerical (list) : Liste des variables catégorielle\n",
    "    - features (list) : Liste des colonnes à standardiser\n",
    "    \"\"\"\n",
    "    # Sélection des variables non numériques\n",
    "    non_numerical = df.select_dtypes(exclude=['number']).columns.to_list()\n",
    "    # Sélection des colonnes à traiter (toutes sauf la valeur à prédire)\n",
    "    features = df.drop('MONTANT', axis=1).columns\n",
    "\n",
    "    # Dictionnaire où seront stockés les LabelEncoder et Scaler afin\n",
    "    # de pouvoir inverser la labellisation et la standardisation\n",
    "    encoders = {}\n",
    "    scalers = {}\n",
    "\n",
    "    # Encodage des variables catégorielles\n",
    "    for col in non_numerical:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        encoders[col] = le\n",
    "    # Normalisation des données\n",
    "    for col in features:\n",
    "        scaler = StandardScaler()\n",
    "        df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
    "        scalers[col] = scaler\n",
    "    return df,encoders,scalers, non_numerical, features\n",
    "\n",
    "def reverse_scal_encod(df : pd.DataFrame, encoders : dict, scalers : dict,\n",
    "                       non_numerical: list, features: list) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Fonction permettant d'inverser la standardisation puis la labellisation  \n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame) : Data frame qui a été labellisé et standardisé  \n",
    "    - encoders (dict) : Dictionnaire contenant les encodeurs pour chaque variable catégorielle\n",
    "    - scalers (dict) : Dictionnaire contenant les scalers pour chaque variable numérique\n",
    "    - non_numerical (list) : Liste des variables catégorielle\n",
    "    - features (list) : Liste des colonnes à standardiser\n",
    "    \n",
    "    Returns:\n",
    "    - df (pd.DataFrame) : Data frame avec les valeurs d'origine\n",
    "    \"\"\"\n",
    "    # Inversion de la standardisation des données\n",
    "    for col in features:\n",
    "        scaler = scalers[col]\n",
    "        df[col] = scaler.inverse_transform(df[col].values.reshape(-1, 1))\n",
    "\n",
    "    # Inversion de l'encodage des variables catégorielles\n",
    "    for col in non_numerical:\n",
    "        le = encoders[col]\n",
    "        df[col] = le.inverse_transform(df[col].astype(int))\n",
    "    return df\n",
    "\n",
    "# Labellisation et standardisation\n",
    "df ,encoders,scalers,non_numerical,features = encod_scal(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Séparation des données en un jeu d'entraînement et un jeu de test</h1>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1],df.iloc[:,-1],test_size=0.8,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Entraînement sans MLFlow et sans recherche d'hyperparamètres</h1>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model=RandomForestRegressor()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 12982758013.83\n",
      "Écart de prix moyen : 113941.91\n",
      "R-squared (R2): 0.36\n",
      "Mean Absolute Error (MAE): 85339.07\n",
      "Mean Absolute Percentage Error (MAPE): 14944.62%\n"
     ]
    }
   ],
   "source": [
    "# Performance du modèle\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np \n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Écart de prix moyen : {rmse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La moyenne des erreurs entre prédictions et réalité et de 85 329€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du bien avec le plus grand écart :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation N°144509 : valeur prédite : 772727.0473821196 valeur réelle :  4100 Différence :  -768627.0473821196\n",
      "         SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN    Name_region\n",
      "2329684         139.0        4.0    Appartement  Île-de-France\n"
     ]
    }
   ],
   "source": [
    "ecarts = np.abs(y_pred - y_test)\n",
    "index_ecart_maximum = np.argmax(ecarts)\n",
    "\n",
    "\n",
    "observation = X_test.iloc[index_ecart_maximum,:].to_frame().transpose()\n",
    "print(f\"Observation N°{index_ecart_maximum} :\",\n",
    "          \"valeur prédite :\", y_pred[index_ecart_maximum],\n",
    "          \"valeur réelle : \",y_test.iloc[index_ecart_maximum],\n",
    "          \"Différence : \", y_test.iloc[index_ecart_maximum]-y_pred[index_ecart_maximum])\n",
    "\n",
    "observation = reverse_scal_encod(observation,encoders,scalers,non_numerical,features)\n",
    "print(observation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ici nous pouvons voir qu'il y a encore des valeurs aberrantes, un appartement de 183m² en Île de France est à mon avis impossible !!! \n",
    "=> Regardons le nombre de biens inférieurs à 10 000€ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_region\n",
       "Nouvelle-Aquitaine            2319\n",
       "Auvergne-Rhône-Alpes          2292\n",
       "Occitanie                     1910\n",
       "Bourgogne-Franche-Comté       1549\n",
       "Île-de-France                 1353\n",
       "Grand Est                     1332\n",
       "Pays de la Loire              1119\n",
       "Bretagne                      1094\n",
       "Centre-Val de Loire           1024\n",
       "Provence-Alpes-Côte d'Azur     943\n",
       "Hauts-de-France                941\n",
       "Normandie                      739\n",
       "Guadeloupe                     319\n",
       "Martinique                     313\n",
       "Corse                          199\n",
       "La Réunion                     199\n",
       "Guyane                         126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = encoders[\"Name_region\"]\n",
    "scaler = scalers[\"Name_region\"]\n",
    "detect_100000 = df.loc[df.MONTANT < 10000, :].copy()\n",
    "\n",
    "# Inversion de la standardisation des données\n",
    "detect_100000[\"Name_region\"] = scaler.inverse_transform(detect_100000[\"Name_region\"].values.reshape(-1, 1))\n",
    "\n",
    "# Inversion de l'encodage des variables catégorielles\n",
    "detect_100000[\"Name_region\"] = le.inverse_transform(detect_100000[\"Name_region\"].astype(int))\n",
    "\n",
    "detect_100000[\"Name_region\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion : Après une petite recherche sur le site Leboncoin nous pouvons remarqué que les biens vendus en dessous de 10 000€ sont parfois des caves, places de parking ou des biens acquis en temps partagé(exemple appartement à la montagne). La suppression des outliers n'a à priori pas permis d'enlever ces biens dans l'entraînement du modèle ce qui génère une baisse des performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Entraînement et résultats en enlevant les biens de moins de 10 000€</h1>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 12791619356.05\n",
      "Écart de prix moyen : 113100.04\n",
      "R-squared (R2): 0.36\n",
      "Mean Absolute Error (MAE): 84822.73\n",
      "Mean Absolute Percentage Error (MAPE): 67.70%\n"
     ]
    }
   ],
   "source": [
    "# Récupération des données\n",
    "df = pd.read_csv(\"datas_rds.csv\", low_memory=False)\n",
    "# Sélection des données non nulles\n",
    "df = df.loc[(df.MONTANT>10000) & (df.NB_PIECES>0) & (df.SURFACE_BATI>0),:]\n",
    "# Suppression des valeurs extremes en région Bretagne\n",
    "df = df[~((df.Name_region==\"Bretagne\")&(df.MONTANT>6.5e6))]\n",
    "# Sélection des données\n",
    "df = df.loc[:,[\"SURFACE_BATI\",\"NB_PIECES\",\"NAME_TYPE_BIEN\",\"Name_region\",\"MONTANT\"]]\n",
    "# Suppression des lignes dupliquées\n",
    "df = df.drop_duplicates()\n",
    "# Suppression des outliers afin de moins perturber le modèle lors de l'apprentissage\n",
    "def filtrer_outliers(groupe):\n",
    "    Q1 = groupe['MONTANT'].quantile(0.25)\n",
    "    Q3 = groupe['MONTANT'].quantile(0.75)\n",
    "    IQR = Q3 - Q1 # Range interquartile\n",
    "    # Convention sur la statistique de l'IQR pour determiner les outliers\n",
    "    borne_inf = Q1 - 1.5 * IQR\n",
    "    borne_sup = Q3 + 1.5 * IQR\n",
    "    return groupe[(groupe['MONTANT'] >= borne_inf) & (groupe['MONTANT'] <= borne_sup)]\n",
    "\n",
    "df = df.groupby('Name_region').apply(filtrer_outliers)\n",
    "# Rest de L'index\n",
    "df = df.reset_index(drop=True)\n",
    "# Labellisation et standardisation\n",
    "df, encoders, scalers, non_numerical, features = encod_scal(df) \n",
    "# Split de données\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1],df.iloc[:,-1],test_size=0.8,random_state=42)\n",
    "# Entraînement des données\n",
    "model=RandomForestRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "# Prédiction et métriques\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Écart de prix moyen : {rmse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARAISON DES 5 PREMIERS BIENS /\n",
      "\n",
      "Observation N°0 : valeur prédite : 240757.31 valeur réelle :  144000\n",
      "         SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN         Name_region\n",
      "1430383          73.0        3.0    Appartement  Nouvelle-Aquitaine\n",
      "------------------------------------------------------------\n",
      "Observation N°1 : valeur prédite : 109610.91 valeur réelle :  84000\n",
      "         SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN         Name_region\n",
      "1260339          23.0        1.0    Appartement  Nouvelle-Aquitaine\n",
      "------------------------------------------------------------\n",
      "Observation N°2 : valeur prédite : 116133.66 valeur réelle :  247100\n",
      "         SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN Name_region\n",
      "1074465          41.0        2.0    Appartement   Normandie\n",
      "------------------------------------------------------------\n",
      "Observation N°3 : valeur prédite : 134499.77 valeur réelle :  38000\n",
      "         SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN Name_region\n",
      "1485248          50.0        2.0    Appartement   Occitanie\n",
      "------------------------------------------------------------\n",
      "Observation N°4 : valeur prédite : 112619.32 valeur réelle :  119000\n",
      "         SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN       Name_region\n",
      "1823055          66.0        4.0    Appartement  Pays de la Loire\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"COMPARAISON DES 5 PREMIERS BIENS /\\n\")\n",
    "for i in range(5):\n",
    "    observation = X_test.iloc[i,:].to_frame().transpose()\n",
    "    print(f\"Observation N°{i} :\",\n",
    "          \"valeur prédite :\", round(model.predict(observation)[0],2),\n",
    "          \"valeur réelle : \",y_test.iloc[i])\n",
    "    \n",
    "    observation = reverse_scal_encod(observation,encoders,scalers,non_numerical,features)\n",
    "    print(observation)\n",
    "    print(\"------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion : Le R2 score n'a pas évolué et le MAE a légèrement diminué mais en ce qui concerne MAPE on a drastiquement diminué, passant de 15 000% à 64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation N°1491556 : valeur prédite : 785740.7416666666 valeur réelle :  16000 Différence :  -769740.7416666666\n",
      "         SURFACE_BATI  NB_PIECES NAME_TYPE_BIEN    Name_region\n",
      "2311013         148.0        4.0    Appartement  Île-de-France\n"
     ]
    }
   ],
   "source": [
    "ecarts = np.abs(y_pred - y_test)\n",
    "index_ecart_maximum = np.argmax(ecarts)\n",
    "\n",
    "\n",
    "observation = X_test.iloc[index_ecart_maximum,:].to_frame().transpose()\n",
    "print(f\"Observation N°{index_ecart_maximum} :\",\n",
    "          \"valeur prédite :\", y_pred[index_ecart_maximum],\n",
    "          \"valeur réelle : \",y_test.iloc[index_ecart_maximum],\n",
    "          \"Différence : \", y_test.iloc[index_ecart_maximum]-y_pred[index_ecart_maximum])\n",
    "\n",
    "observation = reverse_scal_encod(observation,encoders,scalers,non_numerical,features)\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Sauvegarde des encoders, scalers et du model en local</h1>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./scalers']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, './model')\n",
    "joblib.dump(encoders, './encoders')\n",
    "joblib.dump(scalers, './scalers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; background-color:gray; padding:0px;\">\n",
    "  <h1 style=\"color:white;\">Sauvegarde des encoders, scalers et du model dans S3</h1>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'objet model a été uploadé avec succès vers le bucket s3\n",
      "L'objet scalers a été uploadé avec succès vers le bucket s3\n",
      "L'objet encoders a été uploadé avec succès vers le bucket s3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"/home/kevin/workspace/PCO/certif_app_immo/model/.venv/.local\")\n",
    "# Identifiant du bucket\n",
    "aws_access_key_id = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "bucket = os.environ.get(\"BUCKET_NAME\")\n",
    "\n",
    "# Initialiser le client S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "model_encoders_scalers=[\"model\",\"scalers\",\"encoders\"]\n",
    "for obj in model_encoders_scalers:\n",
    "    local_path=f\"/home/kevin/workspace/PCO/certif_app_immo/model/{obj}\"\n",
    "    s3_path=f\"app_immo/joblib/{obj}\"\n",
    "    s3.upload_file(local_path, bucket, s3_path)\n",
    "    print(f\"L'objet {obj} a été uploadé avec succès vers le bucket s3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
