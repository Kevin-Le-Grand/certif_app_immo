{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"background-color:blue; color:white; padding: 5px;\">Entrainment de modèles avec RandomForest Regressor<br></h1>\n",
    "</h4><span style=\"background-color:red; color:white; padding: 5px;\">Utiliser un outil permettant de rafraîchir la page régulièrement pour éviter la mise en sommeil de MLflow sur Heroku\n",
    "</span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 15:06:21.233462: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-17 15:06:21.653582: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-17 15:06:21.659632: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-17 15:06:23.130683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functions2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Choix des paramètres pour l'entraînement, le stockage sur MLflow et des données à récupérer.</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "#                       Option de filtrage des données\n",
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "# Variable permettant de choisir si on veut traiter les outliers\n",
    "gestion_outliers =True\n",
    "\n",
    "# Nombre de ventes minimum sur une commune pour calculer un prix moyen au m² par commune\n",
    "nb_ventes_mini = 10\n",
    "\n",
    "# Taux de filtrage : \n",
    "# - Le premier élément est le nombre de vente minimum par commune\n",
    "# - Le deuxième élément est le pourcentage de outliers dans une commune\n",
    "#\n",
    "# Exemple pour tx_filtrage =[10,30] les lignes qui seront conservées seront :\n",
    "# Les communes dans lesquelles il restera minimum 10 ventes après suppression des outliers\n",
    "# ET  moins de 30% d'outliers\n",
    "# ET les lignes inférieures à la limite des outliers\n",
    "# tx_filtrage = [0,100] => Suppression des lignes dont le montant est au dessus de la limite des outliers.\n",
    "tx_filtrage =[nb_ventes_mini,30]\n",
    "\n",
    "# Recherche sur une région spécifique si recherche sur toute la France mettre ''\n",
    "region=''\n",
    "\n",
    "# Recherche sur un type de bien spécifique si recherche sur tous les bien mettre ''\n",
    "type_de_bien =''\n",
    "\n",
    "# Inclure la surface du terrain True ou False\n",
    "surface_terrain = True\n",
    "\n",
    "# Nombre de mois pour l'entraînement et le test (train=80% test= 20%)\n",
    "# Exemple si 15 mois environ 12 mois pour l'entraînement et 3 mois pour le test\n",
    "# Mettre None pour utiliser toutes les données disponible\n",
    "nb_mois=30\n",
    "\n",
    "#*******************  Pour ajouter d'autres variables :  ***********************\n",
    "#*********  modifier la requête dans la fonction construcion_requete() ********* \n",
    "\n",
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "#                       Configuration de GridSearchCV\n",
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100],\n",
    "    'max_depth': [10,20],\n",
    "    'min_samples_split': [2,5]\n",
    "    }   \n",
    "cv=5\n",
    "\n",
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "#                       Configuration de mlfow\n",
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "# Configuration de mlflow\n",
    "uri_tracking = \"https://mlflowimmoappkevleg-737621d410d0.herokuapp.com/\"\n",
    "experiment_name = \"RandomForestRegressor\"\n",
    "\n",
    "# runs à effectuer all_datas 15months all_datas_surface_terrain 15months_surface_terrain)\n",
    "# run_name = f\"{region}_{'Appartement_Maison' if len(type_de_bien)==0 else type_de_bien}\"\\\n",
    "#     f\"_{nb_mois}months_GridSearch_GestionOutliers_{'oui' if gestion_outliers==True else 'non'}\"\\\n",
    "#     f\"_{'' if surface_terrain==False else 'surface_terrain'}\"\n",
    "run_name =\"NameRegion_NameTypeBien_Appt_Maison_GestionOutliersOui_SurfaceTerrainOui_30Mois\"\n",
    "model_name = f\"RFR_{run_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Création de la requête </span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # Table pour compter le nombre de ventes par commune\n",
      "    WITH nb_ventes_mini AS(\n",
      "    SELECT\n",
      "        ID_COMMUNE AS ID_COMMUNE,\n",
      "        count(*) nb_ventes_par_commune\n",
      "    FROM VENTES \n",
      "    WHERE DATE_MUTATION >= DATE_SUB((SELECT MAX(DATE_MUTATION) FROM VENTES), INTERVAL 30 MONTH)\n",
      "    GROUP BY ID_COMMUNE\n",
      "    )\n",
      "\n",
      "    # Selection des variables voulues pour l'entraînement du modèle\n",
      "    SELECT \n",
      "        V.SURFACE_BATI,\n",
      "        V.ID_COMMUNE,\n",
      "        V.DATE_MUTATION,\n",
      "        T.NAME_TYPE_BIEN,\n",
      "        R.Name_region,\n",
      "        V.SURFACE_TERRAIN,\n",
      "        V.MONTANT\n",
      "    FROM VENTES V\n",
      "    INNER JOIN TYPES_BIENS as T ON V.ID_TYPE_BIEN = T.ID_TYPE_BIEN\n",
      "    INNER JOIN COMMUNES AS C ON V.ID_COMMUNE = C.ID_COMMUNE\n",
      "    INNER JOIN DEPARTEMENTS AS D ON C.ID_DEPT = D.ID_DEPT\n",
      "    INNER JOIN REGIONS R ON D.ID_REGION = R.ID_REGION\n",
      "    WHERE R.Name_region NOT IN('Martinique', 'Guyane', 'La Réunion', 'Mayotte', 'Guadeloupe')  AND V.DATE_MUTATION >= DATE_SUB((SELECT MAX(DATE_MUTATION) FROM VENTES), INTERVAL 30 MONTH)\n",
      "    AND V.MONTANT>15000  AND V.MONTANT<6500000\n",
      "    AND V.SURFACE_BATI>0\n",
      "    AND V.NB_PIECES>0\n",
      "    AND V.ID_COMMUNE IN (\n",
      "        SELECT \n",
      "            ID_COMMUNE \n",
      "        FROM nb_ventes_mini \n",
      "        WHERE nb_ventes_par_commune>=10)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "where_clause, query = construcion_requete(region,\n",
    "                        type_de_bien,\n",
    "                        nb_ventes_mini,\n",
    "                        surface_terrain,\n",
    "                        nb_mois)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Chargement des données et suppression des outliers. </span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données en cours...\n",
      "Création engine sqlalchemy OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données ok\n",
      "Il y a 23205 communes avec plus de 10 ventes avant suppression des outliers, pour un total de 2406641 ventes\n",
      "Chargement des données en cours...\n",
      "Création engine sqlalchemy OK\n",
      "Chargement des données ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_COMMUNE</th>\n",
       "      <th>nb_outliers</th>\n",
       "      <th>total_ventes</th>\n",
       "      <th>ventes_restantes</th>\n",
       "      <th>NAME_COMMUNE</th>\n",
       "      <th>pourcentage_ventes_retirees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33063</td>\n",
       "      <td>2591</td>\n",
       "      <td>14245</td>\n",
       "      <td>11654</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>18.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92012</td>\n",
       "      <td>2185</td>\n",
       "      <td>5056</td>\n",
       "      <td>2871</td>\n",
       "      <td>Boulogne-Billancourt</td>\n",
       "      <td>43.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06088</td>\n",
       "      <td>2105</td>\n",
       "      <td>22827</td>\n",
       "      <td>20722</td>\n",
       "      <td>Nice</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92051</td>\n",
       "      <td>1969</td>\n",
       "      <td>2731</td>\n",
       "      <td>762</td>\n",
       "      <td>Neuilly-sur-Seine</td>\n",
       "      <td>72.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44109</td>\n",
       "      <td>1620</td>\n",
       "      <td>16226</td>\n",
       "      <td>14606</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>9.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31555</td>\n",
       "      <td>1481</td>\n",
       "      <td>24005</td>\n",
       "      <td>22524</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>06029</td>\n",
       "      <td>1466</td>\n",
       "      <td>7787</td>\n",
       "      <td>6321</td>\n",
       "      <td>Cannes</td>\n",
       "      <td>18.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92044</td>\n",
       "      <td>1277</td>\n",
       "      <td>2914</td>\n",
       "      <td>1637</td>\n",
       "      <td>Levallois-Perret</td>\n",
       "      <td>43.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78646</td>\n",
       "      <td>1231</td>\n",
       "      <td>3017</td>\n",
       "      <td>1786</td>\n",
       "      <td>Versailles</td>\n",
       "      <td>40.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94068</td>\n",
       "      <td>1200</td>\n",
       "      <td>3524</td>\n",
       "      <td>2324</td>\n",
       "      <td>Saint-Maur-des-Fossés</td>\n",
       "      <td>34.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_COMMUNE  nb_outliers  total_ventes  ventes_restantes  \\\n",
       "0      33063         2591         14245             11654   \n",
       "1      92012         2185          5056              2871   \n",
       "2      06088         2105         22827             20722   \n",
       "3      92051         1969          2731               762   \n",
       "4      44109         1620         16226             14606   \n",
       "5      31555         1481         24005             22524   \n",
       "6      06029         1466          7787              6321   \n",
       "7      92044         1277          2914              1637   \n",
       "8      78646         1231          3017              1786   \n",
       "9      94068         1200          3524              2324   \n",
       "\n",
       "            NAME_COMMUNE  pourcentage_ventes_retirees  \n",
       "0               Bordeaux                        18.19  \n",
       "1   Boulogne-Billancourt                        43.22  \n",
       "2                   Nice                         9.22  \n",
       "3      Neuilly-sur-Seine                        72.10  \n",
       "4                 Nantes                         9.98  \n",
       "5               Toulouse                         6.17  \n",
       "6                 Cannes                        18.83  \n",
       "7       Levallois-Perret                        43.82  \n",
       "8             Versailles                        40.80  \n",
       "9  Saint-Maur-des-Fossés                        34.05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'outliers : 142947\n",
      "Nombre de commune avec des outliers : 8574\n",
      "Nombre de communes contenant des outliers et pour lesquels ilreste plus de 10 ventes après suppression des outliers : 7811\n",
      "Nombre de communes avec plus de 30% de ventes retirées : 508\n",
      "Nombre de communes qui seront retirées : 1105\n",
      "Nombre de ventes restantes après suppression des outlier et après filtrage : 2205382\n",
      "Il y a donc eu 8.36% de lignes supprimées après filtrage\n"
     ]
    }
   ],
   "source": [
    "df = loading_data(query)\n",
    "\n",
    "if gestion_outliers==True:\n",
    "    df=filtrage(df,tx_filtrage,where_clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Entraînement du modèle et stockage des données avec MLflow. </span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split des données en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/workspace/PCO/certif_app_immo/model/functions2.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['M2'] = df_train['MONTANT'] / df_train['SURFACE_BATI']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split OK\n",
      "Normalisation des données en cours...\n",
      "Normalisation des données OK\n",
      "Entraînement en cours ...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time= 2.7min\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time= 3.0min\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time= 2.5min\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time= 2.4min\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time= 2.2min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time= 5.2min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time= 5.1min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time= 5.0min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time= 5.3min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time= 5.3min\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time= 2.8min\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time= 3.2min\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time= 2.7min\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time= 2.5min\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time= 3.1min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time= 5.9min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time= 5.8min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time= 6.2min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time= 5.7min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time= 5.6min\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time= 5.6min\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time= 5.2min\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time= 5.0min\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time= 4.7min\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time= 4.4min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=11.5min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=10.5min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=10.9min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time= 9.8min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time= 9.2min\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time= 4.8min\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time= 5.2min\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time= 5.2min\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time= 4.7min\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time= 4.6min\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=10.4min\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time= 9.7min\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time= 9.7min\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time= 9.6min\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time= 9.1min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_mae</th>\n",
       "      <th>split1_test_mae</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_mae</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>split0_test_r2</th>\n",
       "      <th>split1_test_r2</th>\n",
       "      <th>split2_test_r2</th>\n",
       "      <th>split3_test_r2</th>\n",
       "      <th>split4_test_r2</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>rank_test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153.089401</td>\n",
       "      <td>15.360142</td>\n",
       "      <td>1.415070</td>\n",
       "      <td>0.184803</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>-45663.615047</td>\n",
       "      <td>-43297.756788</td>\n",
       "      <td>...</td>\n",
       "      <td>944.839350</td>\n",
       "      <td>4</td>\n",
       "      <td>0.674863</td>\n",
       "      <td>0.670609</td>\n",
       "      <td>0.672456</td>\n",
       "      <td>0.668214</td>\n",
       "      <td>0.624905</td>\n",
       "      <td>0.662209</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308.738683</td>\n",
       "      <td>5.931081</td>\n",
       "      <td>2.684948</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>-45658.206608</td>\n",
       "      <td>-43298.002859</td>\n",
       "      <td>...</td>\n",
       "      <td>945.622370</td>\n",
       "      <td>3</td>\n",
       "      <td>0.675054</td>\n",
       "      <td>0.670649</td>\n",
       "      <td>0.672547</td>\n",
       "      <td>0.668384</td>\n",
       "      <td>0.624915</td>\n",
       "      <td>0.662310</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169.900941</td>\n",
       "      <td>14.742073</td>\n",
       "      <td>1.529962</td>\n",
       "      <td>0.266720</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>-45677.308364</td>\n",
       "      <td>-43287.750152</td>\n",
       "      <td>...</td>\n",
       "      <td>949.900133</td>\n",
       "      <td>2</td>\n",
       "      <td>0.674771</td>\n",
       "      <td>0.670845</td>\n",
       "      <td>0.672640</td>\n",
       "      <td>0.668388</td>\n",
       "      <td>0.624969</td>\n",
       "      <td>0.662323</td>\n",
       "      <td>0.018794</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>346.992437</td>\n",
       "      <td>12.754522</td>\n",
       "      <td>3.080674</td>\n",
       "      <td>0.260333</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>-45657.642598</td>\n",
       "      <td>-43284.856922</td>\n",
       "      <td>...</td>\n",
       "      <td>949.739342</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675088</td>\n",
       "      <td>0.670823</td>\n",
       "      <td>0.672517</td>\n",
       "      <td>0.668420</td>\n",
       "      <td>0.624960</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293.523154</td>\n",
       "      <td>26.189132</td>\n",
       "      <td>5.972636</td>\n",
       "      <td>1.504375</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>-47372.494773</td>\n",
       "      <td>-44406.570703</td>\n",
       "      <td>...</td>\n",
       "      <td>1042.111403</td>\n",
       "      <td>8</td>\n",
       "      <td>0.648784</td>\n",
       "      <td>0.654204</td>\n",
       "      <td>0.658089</td>\n",
       "      <td>0.658129</td>\n",
       "      <td>0.612813</td>\n",
       "      <td>0.646404</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     153.089401     15.360142         1.415070        0.184803   \n",
       "1     308.738683      5.931081         2.684948        0.234375   \n",
       "2     169.900941     14.742073         1.529962        0.266720   \n",
       "3     346.992437     12.754522         3.080674        0.260333   \n",
       "4     293.523154     26.189132         5.972636        1.504375   \n",
       "\n",
       "  param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "0              10                       2                 50   \n",
       "1              10                       2                100   \n",
       "2              10                       5                 50   \n",
       "3              10                       5                100   \n",
       "4              20                       2                 50   \n",
       "\n",
       "                                              params  split0_test_mae  \\\n",
       "0  {'max_depth': 10, 'min_samples_split': 2, 'n_e...    -45663.615047   \n",
       "1  {'max_depth': 10, 'min_samples_split': 2, 'n_e...    -45658.206608   \n",
       "2  {'max_depth': 10, 'min_samples_split': 5, 'n_e...    -45677.308364   \n",
       "3  {'max_depth': 10, 'min_samples_split': 5, 'n_e...    -45657.642598   \n",
       "4  {'max_depth': 20, 'min_samples_split': 2, 'n_e...    -47372.494773   \n",
       "\n",
       "   split1_test_mae  ...  std_test_mae  rank_test_mae  split0_test_r2  \\\n",
       "0    -43297.756788  ...    944.839350              4        0.674863   \n",
       "1    -43298.002859  ...    945.622370              3        0.675054   \n",
       "2    -43287.750152  ...    949.900133              2        0.674771   \n",
       "3    -43284.856922  ...    949.739342              1        0.675088   \n",
       "4    -44406.570703  ...   1042.111403              8        0.648784   \n",
       "\n",
       "   split1_test_r2  split2_test_r2  split3_test_r2  split4_test_r2  \\\n",
       "0        0.670609        0.672456        0.668214        0.624905   \n",
       "1        0.670649        0.672547        0.668384        0.624915   \n",
       "2        0.670845        0.672640        0.668388        0.624969   \n",
       "3        0.670823        0.672517        0.668420        0.624960   \n",
       "4        0.654204        0.658089        0.658129        0.612813   \n",
       "\n",
       "   mean_test_r2  std_test_r2  rank_test_r2  \n",
       "0      0.662209     0.018780             4  \n",
       "1      0.662310     0.018826             3  \n",
       "2      0.662323     0.018794             2  \n",
       "3      0.662362     0.018827             1  \n",
       "4      0.646404     0.017140             8  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ré-entraînement avec les meilleurs hyperparamètres en cours...\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train, X_test, y_test = split_with_m2(df)\n",
    "\n",
    "X_train,X_test,encoders,scalers =  encod_scal(X_train,X_test)\n",
    "\n",
    "model, best_params = train_model_randomforest(X_train,y_train, param_grid, cv)\n",
    "\n",
    "# Tracé et enregistrement du graphique permettant de savoir si le modèle contient suffisamment de données.\n",
    "images = plot_validation_learning_curve(model, X_train, y_train)\n",
    "\n",
    "param_mlflow(uri_tracking=uri_tracking,\n",
    "        experiment_name=experiment_name, run_name=run_name,\n",
    "        best_params=best_params,\n",
    "        model=model, model_name=model_name,\n",
    "        X_test=X_test, y_test=y_test,\n",
    "        encoders=encoders,scalers=scalers,\n",
    "        images = images).log_mlflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
