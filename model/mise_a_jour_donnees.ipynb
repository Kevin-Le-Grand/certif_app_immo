{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"background-color:blue; color:white; padding: 5px;\">Notebook à executer lorsqu'il y a de nouvelles données disponible sur data.gouv.fr<br></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 23:06:52.874826: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-18 23:06:52.949114: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-18 23:06:52.950965: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-18 23:06:54.054552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from functions2 import *\n",
    "\n",
    "# Librairies pour la décompression de fichiers et système\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import sys\n",
    "\n",
    "# Librairies pour le scrapping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Visualisation de données\n",
    "import pandas as pd\n",
    "\n",
    "# datas processing\n",
    "import datas_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Récupération des données disponible et insertion dans la table<br></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018/', '2019/', '2020/', '2021/', '2022/', '2023/']\n",
      "Nombre de lignes ne pouvant être insérées : 23049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_MUTATION</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>NUMERO_RUE</th>\n",
       "      <th>RUE</th>\n",
       "      <th>CODE_POSTAL</th>\n",
       "      <th>ID_COMMUNE</th>\n",
       "      <th>ID_TYPE_BIEN</th>\n",
       "      <th>NB_PIECES</th>\n",
       "      <th>SURFACE_BATI</th>\n",
       "      <th>SURFACE_TERRAIN</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DEPENDANCES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>1070000</td>\n",
       "      <td>184</td>\n",
       "      <td>ALL DES HETRES</td>\n",
       "      <td>01630</td>\n",
       "      <td>01354</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>6.020119</td>\n",
       "      <td>46.247305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>206500</td>\n",
       "      <td>294</td>\n",
       "      <td>RTE DE MONTREVEL</td>\n",
       "      <td>01340</td>\n",
       "      <td>01024</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>3462</td>\n",
       "      <td>5.155628</td>\n",
       "      <td>46.294436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>449286</td>\n",
       "      <td>339</td>\n",
       "      <td>RTE DE LA LIGNEE</td>\n",
       "      <td>24200</td>\n",
       "      <td>24520</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>61761</td>\n",
       "      <td>1.206266</td>\n",
       "      <td>44.882129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>258000</td>\n",
       "      <td>1455</td>\n",
       "      <td>RTE VICTOR HUGO</td>\n",
       "      <td>24330</td>\n",
       "      <td>24053</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>1905</td>\n",
       "      <td>0.788944</td>\n",
       "      <td>45.129127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>164400</td>\n",
       "      <td>0</td>\n",
       "      <td>LE BOST</td>\n",
       "      <td>24630</td>\n",
       "      <td>24218</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>2683</td>\n",
       "      <td>1.083713</td>\n",
       "      <td>45.491963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DATE_MUTATION  MONTANT NUMERO_RUE               RUE CODE_POSTAL ID_COMMUNE  \\\n",
       "0    2023-01-05  1070000        184    ALL DES HETRES       01630      01354   \n",
       "1    2023-01-14   206500        294  RTE DE MONTREVEL       01340      01024   \n",
       "2    2023-01-12   449286        339  RTE DE LA LIGNEE       24200      24520   \n",
       "3    2023-01-20   258000       1455   RTE VICTOR HUGO       24330      24053   \n",
       "4    2023-01-18   164400          0           LE BOST       24630      24218   \n",
       "\n",
       "   ID_TYPE_BIEN  NB_PIECES  SURFACE_BATI  SURFACE_TERRAIN  LONGITUDE  \\\n",
       "0             1          8           233                0   6.020119   \n",
       "1             2          5           144             3462   5.155628   \n",
       "2             2          4           129            61761   1.206266   \n",
       "3             2          5           108             1905   0.788944   \n",
       "4             2          4           108             2683   1.083713   \n",
       "\n",
       "    LATITUDE  DEPENDANCES  \n",
       "0  46.247305            1  \n",
       "1  46.294436            1  \n",
       "2  44.882129            1  \n",
       "3  45.129127            0  \n",
       "4  45.491963            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération des codes communes , noms communes et code départements disponibles sur l'api \n",
    "url = \"https://geo.api.gouv.fr/communes\"\n",
    "response = requests.get(url)\n",
    "data_communes = response.json()\n",
    "df_communes = pd.DataFrame(data_communes)\n",
    "df_communes = df_communes.loc[:,[\"code\",\"nom\",\"codeDepartement\"]]\n",
    "df_communes = df_communes.drop_duplicates()\n",
    "df_communes.columns= [\"ID_COMMUNE\",\"NAME_COMMUNE\",\"ID_DEPT\"]\n",
    "liste_ID_COMMUNES = df_communes.ID_COMMUNE.to_list()\n",
    "\n",
    "# URL de la page web\n",
    "url = 'https://files.data.gouv.fr/geo-dvf/latest/csv/'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Utilisez BeautifulSoup pour analyser le HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Trouver toutes les balises <a>\n",
    "a_tags = soup.find_all('a')\n",
    "annees=[]\n",
    "# Parcourir chaque balise <a> et extraire le texte ainsi que la date/heure\n",
    "for a_tag in a_tags:\n",
    "    name = a_tag.text.strip()\n",
    "    if name!=\"../\":\n",
    "        annees.append(name)\n",
    "print(annees)\n",
    "\n",
    "url = f'https://files.data.gouv.fr/geo-dvf/latest/csv/{annees[-1]}'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Trouver la balise 'a' qui contient les liens de téléchargement\n",
    "csv_element = soup.find('pre').find('a', {'href': \"full.csv.gz\"})\n",
    "csv_link = urljoin(url, csv_element['href'])\n",
    "\n",
    "# Téléchargement des datas et conversion en data frame\n",
    "csv_response = requests.get(csv_link)\n",
    "if csv_response.status_code == 200:\n",
    "    # Utilisation du buffer pour décompresser le fichier .gz\n",
    "    try :\n",
    "        with BytesIO(csv_response.content) as file_buffer:\n",
    "            with gzip.GzipFile(fileobj=file_buffer, mode='rb') as gz_file:\n",
    "                df = pd.read_csv(gz_file, low_memory=False)\n",
    "    except Exception as e:\n",
    "        print(\"Erreur dans la transformation des données en data frame :\",e)\n",
    "\n",
    "# Selection des données\n",
    "df = datas_processing.select_datas(df)\n",
    "\n",
    "# Gestion des valeurs manquantes :\n",
    "df = datas_processing.nan_management(df)\n",
    "\n",
    "# Adaptation des données du data frame au format de la base de données\n",
    "df = datas_processing.format_data(df)\n",
    "\n",
    "# Groupement des données sur une seule ligne par id_mutation (vente)\n",
    "df = datas_processing.grouped_datas(df)\n",
    "\n",
    "# Adaptation des données avec les variables et clés étrangères de la bdd\n",
    "df = datas_processing.features_and_foreign_keys(df,liste_ID_COMMUNES)\n",
    "\n",
    "#Suppression des lignes dupliquées\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Date la plus ancienne dans les nouvelles données\n",
    "date_plus_ancienne_nouvelles_donnees = df['DATE_MUTATION'].min()\n",
    "print(date_plus_ancienne_nouvelles_donnees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connection_with_sqlalchemy(\"datagouv\")\n",
    "query = \"SELECT MAX(DATE_MUTATION) FROM VENTES;\"\n",
    "dates_bdd= pd.read_sql(con=engine.connect(), sql=text(query))\n",
    "date_plus_recente_bdd = dates_bdd['DATE_MUTATION'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "#   Suppression de ventes identiques entre les nouvelles données récupérées\n",
    "#                    et celles stockées en base de données\n",
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "transaction = engine.begin()\n",
    "try:\n",
    "    # Récupération la date la plus ancienne dans les nouvelles données récupérées\n",
    "    date_plus_ancienne = df['DATE_MUTATION'].min()\n",
    "    print(date_plus_ancienne)\n",
    "    # Requête pour supprimer les lignes avec une date supérieure ou égale à date_plus_ancienne\n",
    "    query_delete = f\"DELETE FROM VENTES WHERE DATE_MUTATION >= '{date_plus_ancienne}';\"\n",
    "    engine.execute(query_delete)\n",
    "\n",
    "    # Validez la transaction\n",
    "    transaction.commit()\n",
    "    print(\"Transaction validée avec succès.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # En cas d'erreur, annulez la transaction\n",
    "    print(f\"Erreur : {e}\")\n",
    "    transaction.rollback()\n",
    "    print(\"Transaction annulée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "#                   Insertion de nouvelles données\n",
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "transaction = engine.begin()\n",
    "try:\n",
    "    # Insère les données dans la table VENTES\n",
    "    df.to_sql(name='VENTES', con=engine, if_exists='append', index=False)\n",
    "    \n",
    "    # Valide la transaction\n",
    "    transaction.commit()\n",
    "    print(\"Transaction validée avec succès.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # En cas d'erreur, annule la transaction\n",
    "    print(f\"Erreur : {e}\")\n",
    "    transaction.rollback()\n",
    "    print(\"Transaction annulée.\")\n",
    "\n",
    "finally:\n",
    "    # Libère les ressources de la connexion\n",
    "    transaction.close()\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Stockage de la date du fichier dans une table postgre ...<br></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de la date de mise à jour du fichier\n",
    "date_element = soup.find('pre').contents[-1].strip()\n",
    "date_element = date_element.split(\" \")[0]\n",
    "print(date_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Entraînement d'un modèle<br></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se baser sur les modèles créé dans mlflow et entraîner un modèle sur les mêmes paramètres\n",
    "# Enregistrer dans mlflow, experiment : prod_{date_du_jour}\n",
    "gestion_outliers =True\n",
    "nb_ventes_mini = 10\n",
    "tx_filtrage =[nb_ventes_mini,30]\n",
    "region=''\n",
    "type_de_bien =''\n",
    "surface_terrain = True\n",
    "nb_mois=15\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10],\n",
    "    'learning_rate': [0.1],\n",
    "    'min_child_weight': [1,3,5],\n",
    "    'alpha' : [0.5], \n",
    "    'lambda' : [0.5]\n",
    "}\n",
    "cv=5\n",
    "uri_tracking = \"https://mlflowimmoappkevleg-737621d410d0.herokuapp.com/\"\n",
    "experiment_name = \"En_Production\"\n",
    "\n",
    "# runs à effectuer all_datas 15months all_datas_surface_terrain 15months_surface_terrain)\n",
    "run_name = f\"{region}_{'Appartement_Maison' if len(type_de_bien)==0 else type_de_bien}\"\\\n",
    "     f\"_{nb_mois}months_GridSearch_GestionOutliers_{'oui' if gestion_outliers==True else 'non'}\"\\\n",
    "     f\"_{'' if surface_terrain==False else 'surface_terrain'}\"\n",
    "\n",
    "model_name = f\"Production_XGB_{run_name}\"\n",
    "\n",
    "where_clause, query = construcion_requete(region,\n",
    "                        type_de_bien,\n",
    "                        nb_ventes_mini,\n",
    "                        surface_terrain,\n",
    "                        nb_mois)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loading_data(query)\n",
    "\n",
    "if gestion_outliers==True:\n",
    "    df=filtrage(df,tx_filtrage,where_clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train, X_test, y_test = split_with_m2(df)\n",
    "\n",
    "X_train,X_test,encoders,scalers =  encod_scal(X_train,X_test)\n",
    "\n",
    "model, best_params = train_model_xgboost(X_train,y_train, param_grid, cv)\n",
    "\n",
    "# Tracé et enregistrement du graphique permettant de savoir si le modèle contient suffisamment de données.\n",
    "images = plot_validation_learning_curve(model, X_train, y_train)\n",
    "\n",
    "param_mlflow(uri_tracking=uri_tracking,\n",
    "        experiment_name=experiment_name, run_name=run_name,\n",
    "        best_params=best_params,\n",
    "        model=model, model_name=model_name,\n",
    "        X_test=X_test, y_test=y_test,\n",
    "        encoders=encoders,scalers=scalers,\n",
    "        images = images).log_mlflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Créer un csv pour être utilisé dans streamlit<br></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour éviter de trop requêter sur rds mais aussi avoir une execution rapide de l'application.\n",
    "# Récupérer les données Region, département, communes, prix_M²/mois sur la dernière année ou \n",
    "# les deux dernières années suivant le modèle utilisé et par type de bien\n",
    "df = loading_data(\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"background-color:grey; color:white; padding: 5px;\">Transformation du dataframe en csv et stockage dans AWS s3<br></h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
