{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import io\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "import mlflow\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"/home/kevin/workspace/PCO/certif_app_immo/api/.venv/.local\")\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "#           Configuration S3\n",
    "#----------------------------------------------------------------------\n",
    "# Remplacez ces valeurs par les vôtres\n",
    "aws_access_key_id = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "bucket = os.environ.get(\"BUCKET_NAME\")\n",
    "\n",
    "# Initialiser le client S3\n",
    "s3 = boto3.client('s3',\n",
    "                  region_name=\"eu-west-3\",\n",
    "                  aws_access_key_id=aws_access_key_id,\n",
    "                  aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketappcertif 8+fGMz+fI85aKk4ZqeNOe/ZCqoVjQ1hDEoF2UmqB AKIA5JTHFGQOCZZAOYY2\n"
     ]
    }
   ],
   "source": [
    "print(bucket,aws_secret_access_key,aws_access_key_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------\n",
    "#       Récupération d'objet depuis S3\n",
    "#---------------------------------------------------------------\n",
    "# Télécharger l'objet depuis S3 dans un flux BytesIO\n",
    "def load_joblib_from_s3(bucket_name, key):\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    joblib_content = response['Body'].read()\n",
    "\n",
    "    # Charger l'objet depuis le flux BytesIO\n",
    "    loaded_object = joblib.load(io.BytesIO(joblib_content))\n",
    "    return loaded_object\n",
    "\n",
    "scalers = load_joblib_from_s3(bucket,\"app_immo/joblib/scalers\") \n",
    "encoders = load_joblib_from_s3(bucket,\"app_immo/joblib/encoders\") \n",
    "model = load_joblib_from_s3(bucket,\"app_immo/joblib/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encod_scal(n:dict) ->list:\n",
    "    \"\"\"\n",
    "    Fonction servant à labelliser et standardiser les données\n",
    "\n",
    "    Args:\n",
    "    - n (json) : Json contenant les données à prédire\n",
    "    \n",
    "    Returns ::\n",
    "    - transformed_data (list) : Données standardisées de type [0.12,0.55,0.56,0.2]\n",
    "    \"\"\"\n",
    "    transformed_data=[]\n",
    "    transformed_data.append(scalers['SURFACE_BATI'].transform(np.array([n['SURFACE_BATI']]).reshape(-1, 1))[0][0])\n",
    "    transformed_data.append(scalers['NB_PIECES'].transform(np.array([n['NB_PIECES']]).reshape(-1, 1))[0][0])\n",
    "    type_bien = encoders['NAME_TYPE_BIEN'].transform([n['NAME_TYPE_BIEN']])[0] \n",
    "    transformed_data.append(scalers['NAME_TYPE_BIEN'].transform(np.array([type_bien]).reshape(-1, 1))[0][0])\n",
    "    region = encoders['Name_region'].transform([n['Name_region']])[0] \n",
    "    transformed_data.append(scalers['Name_region'].transform(np.array([region]).reshape(-1,1))[0][0])\n",
    "    return transformed_data\n",
    "\n",
    "def predictions(data:list) -> dict:\n",
    "    \"\"\"\n",
    "    Fonction permettant la prédiction \n",
    "\n",
    "    Args :\n",
    "    - data (list): Liste contenant les valeurs à prédire normalisées\n",
    "\n",
    "    Returns :\n",
    "    - response (dict) : Sortie de type : {'reponse': 250000]}\n",
    "    \"\"\"\n",
    "    # Prédiction en utilisant le modèle\n",
    "    data = np.array([data])\n",
    "    pred = model.predict(data)\n",
    "    # Renvoi du dictionnaire contenant la prédiction\n",
    "    return {'reponse':pred[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "n={'SURFACE_BATI':250,\n",
    "   'NB_PIECES':5,\n",
    "   'NAME_TYPE_BIEN':'Maison',\n",
    "   'Name_region':'Normandie',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231247.48100000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/workspace/PCO/certif_app_immo/api/.venv/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = encod_scal(n)\n",
    "prediction= predictions(transform)\n",
    "print(prediction['reponse'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
